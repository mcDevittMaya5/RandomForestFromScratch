{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def splitData(data):\n",
    "    shuffled = data.copy()\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    testCount = int(shuffled.shape[0]*1/3)\n",
    "    trainCount = shuffled.shape[0]-testCount\n",
    "    trainSet = shuffled[0:trainCount]\n",
    "    testSet = shuffled[trainCount:]\n",
    "\n",
    "    return trainSet, testSet\n",
    "\n",
    "\n",
    "def separateInputOutput(dataset):\n",
    "    outputData = dataset[:,3] # Output\n",
    "    inputData = np.concatenate((dataset[:,0:3],dataset[:,4:7],dataset[:,8:10]),axis=1)\n",
    "    return inputData, outputData\n",
    "\n",
    "\n",
    "def getInputAttributeDict():\n",
    "    return {   0 : 'calorific_value',\n",
    "                    1 : 'nitrogen',\n",
    "                    2 : 'turbidity',\n",
    "                    3 : 'alcohol',\n",
    "                    4 : 'sugars',\n",
    "                    5 : 'bitterness',\n",
    "                    6 : 'colour',\n",
    "                    7 : 'degree_of_fermentation'} .copy()\n",
    "\n",
    "\n",
    "def normaliseData(data, normType = \"range\"):\n",
    "    normalisedData = np.zeros(data.shape)\n",
    "    for i in range(normalisedData.shape[1]):\n",
    "        dataColumn = data[:,i].copy()\n",
    "        if normType == \"range\":\n",
    "            maxVal = dataColumn.max()\n",
    "            minVal = dataColumn.min()\n",
    "            for j, val in enumerate(dataColumn):\n",
    "                normalisedData[j,i] = (val-minVal)/(maxVal-minVal)\n",
    "\n",
    "        elif normType == \"z\":\n",
    "            mean = dataColumn.mean()\n",
    "            stdDev =  getStandardDeviation(dataColumn)\n",
    "            for j, val in enumerate(dataColumn):\n",
    "                normalisedData[j,i] = (val-mean)/stdDev\n",
    "    return normalisedData\n",
    "\n",
    "\n",
    "def getStandardDeviation(dataArray):\n",
    "    n = dataArray.shape[0]\n",
    "    mean = dataArray.mean()\n",
    "    sumOfSquareDiffs = 0\n",
    "    for val in dataArray:\n",
    "        sumOfSquareDiffs += (val - mean)**2\n",
    "\n",
    "    variance = sumOfSquareDiffs/(n-1)\n",
    "    stdDev = variance**(1/2)\n",
    "    return stdDev\n",
    "\n",
    "\n",
    "def getUniqueClassCount(listToCount):\n",
    "    classes = []\n",
    "    for item in listToCount:\n",
    "        if item not in classes:\n",
    "            classes.append(item)\n",
    "\n",
    "    counts = []\n",
    "    for itemClass in classes:\n",
    "        counts.append(listToCount.count(itemClass))\n",
    "    return counts, classes\n",
    "\n",
    "\n",
    "def getLeafGini(counts):\n",
    "    total = np.sum(counts)\n",
    "    giniLeaf = 1\n",
    "    for count in counts:\n",
    "        giniLeaf -= (count/total)**2\n",
    "    return giniLeaf\n",
    "\n",
    "\n",
    "def getNodeGini(sortedList, threshold):\n",
    "        lessThan = []\n",
    "        greaterThan = []\n",
    "\n",
    "        for i in range(len(sortedList)):\n",
    "            x = sortedList[i][0]\n",
    "            if x < threshold:\n",
    "                lessThan.append(sortedList[i][1])\n",
    "            else:\n",
    "                greaterThan.append(sortedList[i][1])\n",
    "\n",
    "        countsLT, _ = getUniqueClassCount(lessThan)\n",
    "        countsGT, _ = getUniqueClassCount(greaterThan)\n",
    "        giniLT = getLeafGini(countsLT)\n",
    "        giniGT = getLeafGini(countsGT)\n",
    "        totalCount = len(sortedList)\n",
    "        nodeGini = ((np.sum(countsLT)/totalCount)*giniLT) + ((np.sum(countsGT)/totalCount)*giniGT)\n",
    "        return nodeGini\n",
    "\n",
    "\n",
    "def getMinGiniAndThreshold(inputData, outputData, alreadyUsedAttributes):\n",
    "    inputAttributesMinGinis = []\n",
    "    attributeThresholds = []\n",
    "    attributeIndexes = list(getInputAttributeDict())\n",
    "    for i in alreadyUsedAttributes:\n",
    "        attributeIndexes.remove(i)\n",
    "    \n",
    "    for i in attributeIndexes:\n",
    "        attribute = inputData[:, i].copy() # Single attribute from input data\n",
    "        \n",
    "        inputOutputPairs = []\n",
    "        for j,sample in enumerate(attribute):\n",
    "            inputOutputPairs.append((sample,outputData[j]))\n",
    "        attribute.sort()\n",
    "        sortedInputOutputPairs = [tuple for x in attribute for tuple in inputOutputPairs if tuple[0] == x]\n",
    "\n",
    "        testThresholds = []\n",
    "        for j in range(len(attribute)-1):\n",
    "            testThresholds.append((attribute[j]+attribute[j+1])/2)\n",
    "\n",
    "        nodeGinis = []\n",
    "        for testThresh in testThresholds:\n",
    "            nodeGinis.append(getNodeGini(sortedInputOutputPairs, testThresh))\n",
    "\n",
    "        minNodeGini = min(nodeGinis)\n",
    "        minGiniIndex = nodeGinis.index(minNodeGini)\n",
    "        attributeThreshold = testThresholds[minGiniIndex]\n",
    "\n",
    "        inputAttributesMinGinis.append(minNodeGini)\n",
    "        attributeThresholds.append(attributeThreshold)\n",
    "    return inputAttributesMinGinis, attributeThresholds\n",
    "\n",
    "\n",
    "def createTree(trainIn,trainOut):\n",
    "    attributesUsed = []\n",
    "    return recursiveBranch(trainIn, trainOut, 1, attributesUsed, None)\n",
    "    \n",
    "\n",
    "def recursiveBranch(inputData, outputData, parentGini, attributesUsed, currentNode):\n",
    "    if currentNode == None: # Make root node\n",
    "        minAttributeGinis, attributeThresholds = getMinGiniAndThreshold(inputData, outputData, attributesUsed)\n",
    "        nodeAttributeGini = min(minAttributeGinis)\n",
    "\n",
    "        nodeAttributeIndex = minAttributeGinis.index(nodeAttributeGini)\n",
    "        attributesUsed.append(nodeAttributeIndex)\n",
    "\n",
    "        # print(\"Node attribute index (lowest gini) =\",nodeAttributeIndex)\n",
    "\n",
    "        nodeThreshold = attributeThresholds[minAttributeGinis.index(nodeAttributeGini)]\n",
    "        # print(\"Root node created using attribute {} (has a min gini of {:.5f}). Threshold at this node = {}. Parent node gini = {:.5f}.\".format(nodeAttributeIndex, nodeAttributeGini, nodeThreshold, parentGini))\n",
    "\n",
    "        rootNode = Node(nodeAttributeIndex, nodeThreshold)\n",
    "        branchData(inputData, outputData, nodeAttributeGini, nodeThreshold, nodeAttributeIndex, attributesUsed, rootNode)\n",
    "        # print(\"Back to root\")\n",
    "        return rootNode\n",
    "        \n",
    "    if len(getUniqueClassCount(list(outputData))[0]) == 1:\n",
    "        # print(\"Leaf created - Remaining {} samples are all \\\"{}\\\".\".format(inputData.shape[0], outputData[0]))\n",
    "        currentNode.setValue(outputData)\n",
    "        return\n",
    "\n",
    "    if len(attributesUsed) == len(getInputAttributeDict()): ## -------------------TEST\n",
    "        # print(\"Leaf created - All attributes have been used in current branch.\")\n",
    "        currentNode.setValue(outputData)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        minAttributeGinis, attributeThresholds = getMinGiniAndThreshold(inputData, outputData, attributesUsed)\n",
    "        nodeAttributeGini = min(minAttributeGinis)\n",
    "\n",
    "        # If none of the new ginis is less than parent gini, exit recursion\n",
    "        if parentGini < nodeAttributeGini:\n",
    "            # print(\"Leaf created - Min gini of remaining attributes ({:.5f}) is less than parent node gini ({:.5f}).\".format(nodeAttributeGini, parentGini))\n",
    "            currentNode.setValue(outputData)\n",
    "            return\n",
    "\n",
    "        # Not leaf -> Continue recursion\n",
    "        attributeIndexes = list(getInputAttributeDict()) # Get full attribute list\n",
    "        for i in attributesUsed:                         # Remove previously used attributes\n",
    "            attributeIndexes.remove(i)                  \n",
    "        nodeAttributeIndex = attributeIndexes[minAttributeGinis.index(nodeAttributeGini)] # Get index of new attribute to use \n",
    "        attributesUsed.append(nodeAttributeIndex)                                         # Add to list of used attributes\n",
    "        # print(\"Node attribute index (lowest gini) =\",nodeAttributeIndex)\n",
    "\n",
    "        nodeThreshold = attributeThresholds[minAttributeGinis.index(nodeAttributeGini)] # Get threshold for new node\n",
    "        # print(\"Branch node created using attribute {} (has a min gini of {:.5f}). Threshold at this node = {}. Parent node has gini = {:.5f}.\".format(nodeAttributeIndex, nodeAttributeGini, nodeThreshold, parentGini))\n",
    "        currentNode.setValue(nodeThreshold)\n",
    "        currentNode.setIndex(nodeAttributeIndex)\n",
    "        branchData(inputData, outputData, nodeAttributeGini, nodeThreshold, nodeAttributeIndex, attributesUsed, currentNode)\n",
    "        return\n",
    "    except Exception:\n",
    "        print(Exception)\n",
    "        print(\"Attributes Used = {}\".format(attributesUsed))#[getInputAttributeDict()[i] for i in attributesUsed]))\n",
    "        print(\"OutputData:\",outputData)\n",
    "        print(len(getUniqueClassCount(list(outputData))[0]))\n",
    "        print(len(attributesUsed),len(len(getInputAttributeDict())))\n",
    "\n",
    "\n",
    "def branchData(X, y, splitAttributeGini, splitValue, splitAttributeIndex, attributesUsed, currentNode):\n",
    "    lessThan_X = []\n",
    "    lessThan_y = []\n",
    "    greaterThan_X = []\n",
    "    greaterThan_y = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        if X[i,splitAttributeIndex] < splitValue:\n",
    "            lessThan_X.append(X[i,:])\n",
    "            lessThan_y.append(y[i])\n",
    "        else:\n",
    "            greaterThan_X.append(X[i,:])\n",
    "            greaterThan_y.append(y[i])\n",
    "\n",
    "    # left branch first:\n",
    "    attributesUsed_left = attributesUsed.copy()\n",
    "    attributesUsed_right = attributesUsed.copy()\n",
    "\n",
    "    currentNode.addLeftChild(Node())\n",
    "    currentNode.addRightChild(Node())\n",
    "\n",
    "    # currentNode_right = currentNode.copy()\n",
    "    \n",
    "    lessThan_X = np.asarray(lessThan_X)\n",
    "    lessThan_y = np.asarray(lessThan_y)\n",
    "    # print(\"\\nBranching left...\")\n",
    "    recursiveBranch(lessThan_X, lessThan_y, splitAttributeGini, attributesUsed_left, currentNode.getLeftChild())\n",
    "    # print(\"Finished left branch.\\n\")\n",
    "\n",
    "\n",
    "    # Right branch\n",
    "    greaterThan_X = np.asarray(greaterThan_X)\n",
    "    greaterThan_y = np.asarray(greaterThan_y)\n",
    "    # print(\"\\nBranching right...\")\n",
    "    recursiveBranch(greaterThan_X, greaterThan_y, splitAttributeGini, attributesUsed_right, currentNode.getRightChild())\n",
    "    # print(\"Finished right branch.\\n\")\n",
    "\n",
    "    return lessThan_X,lessThan_y,greaterThan_X,greaterThan_y   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,index=None, value=None):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.index = index\n",
    "        self.value = value #stores value or the classification eg \"ale\"\n",
    "        \n",
    "    def addLeftChild(self,child):\n",
    "        self.left = child\n",
    "    \n",
    "    def getLeftChild(self):\n",
    "        return self.left\n",
    "\n",
    "    def addRightChild(self,child):\n",
    "        self.right = child\n",
    "\n",
    "    def getRightChild(self):\n",
    "        return self.right\n",
    "    \n",
    "    def printTree(self):\n",
    "        if self.left:\n",
    "            self.left.printTree()\n",
    "        print(self.getData())\n",
    "        if self.right:\n",
    "            self.right.printTree()\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value\n",
    "\n",
    "    def setValue(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def setIndex(self, index):\n",
    "        self.index = index\n",
    "    \n",
    "    def getData(self):\n",
    "        return self.index,self.value\n",
    "    \n",
    "    def isLeaf(self):\n",
    "        if (self.left == None) & (self.right == None) & (self.index == None):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(yPredicted,yActual):\n",
    "    correct = 0\n",
    "    for i in range(len(yPredicted)):\n",
    "        if (yPredicted[i] == yActual[i]):\n",
    "            correct += 1\n",
    "    return correct*100/len(yActual)\n",
    "\n",
    "def randomForestClassifierScratch(x,y,N):\n",
    "    forest = []\n",
    "    newX = []\n",
    "    newY = []\n",
    "    for i in range(0,N,1):\n",
    "        newX,newY = bootstrapData(x,y)\n",
    "        root1 = createTree(np.array(newX),np.array(newY))\n",
    "        forest.append(root1)\n",
    "    return np.array(forest)\n",
    "\n",
    "def bootstrapData(X,Y):\n",
    "    newX = []\n",
    "    newY = []\n",
    "    for j in range(len(X)):\n",
    "        randIndex = np.random.randint(len(X))\n",
    "        newX.append(X[randIndex])\n",
    "        newY.append(Y[randIndex])\n",
    "    return newX, newY\n",
    "\n",
    "def predictForest(X,forest):\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        guess = []\n",
    "        for tree in forest:\n",
    "            guess.append(predictTree(X[i],tree))\n",
    "        counts, classes = getUniqueClassCount(list(guess))\n",
    "        majorityClass = classes[counts.index(max(counts))]\n",
    "        predictions.append(majorityClass)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def predictTree(x,root):\n",
    "    treePointer = root\n",
    "    index,value = treePointer.getData()\n",
    "    while treePointer.isLeaf() == False:\n",
    "        if (x[index] < value):\n",
    "            treePointer = treePointer.getLeftChild()\n",
    "            index,value = treePointer.getData()\n",
    "        else:\n",
    "            treePointer = treePointer.getRightChild()\n",
    "            index,value = treePointer.getData()\n",
    "\n",
    "    counts, classes = getUniqueClassCount(list(value)) # get counts of classes in leaf\n",
    "    majorityClass = classes[counts.index(max(counts))]\n",
    "\n",
    "    return majorityClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data:\n",
    "with open(\"beer.txt\", 'r') as f:\n",
    "    lines = np.asarray(f.read().split('\\n'))\n",
    "\n",
    "dataset = []\n",
    "# Split columns and convert numbers from string to float\n",
    "for lineStr in lines: \n",
    "    attributesStr = lineStr.split('\\t') # Separate attributes (currently all strings)\n",
    "    sample = np.empty((len(attributesStr))).astype(object) # Create empty object array for sample data as floats and str\n",
    "    for i, string in enumerate(attributesStr):\n",
    "        try:\n",
    "            sample[i] = float(string)\n",
    "        except ValueError:\n",
    "            sample[i] = string\n",
    "    dataset.append(sample)\n",
    "dataset = np.asarray(dataset)\n",
    "\n",
    "\n",
    "trainSet, testSet = splitData(dataset)\n",
    "\n",
    "testIn, testOut = separateInputOutput(testSet)\n",
    "trainIn, trainOut = separateInputOutput(trainSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N trees plot:\n",
    "ns = np.array([1, 5, 10, 50, 100, 200, 500])\n",
    "accuracies_scratch_train = np.zeros(ns.shape)\n",
    "accuracies_scratch_test = np.zeros(ns.shape)\n",
    "\n",
    "accuracies_scikit_train = np.zeros(ns.shape)\n",
    "accuracies_scikit_test = np.zeros(ns.shape)\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    scratchForest = randomForestClassifierScratch(trainIn,trainOut,n)\n",
    "    scratchPredictions_test = predictForest(testIn,scratchForest)\n",
    "    accuracies_scratch_test[i] = accuracy(scratchPredictions_test, testOut)\n",
    "\n",
    "    scratchPredictions_train = predictForest(trainIn,scratchForest)\n",
    "    accuracies_scratch_train[i] = accuracy(scratchPredictions_train, trainOut)\n",
    "\n",
    "    scikitForest = RandomForestClassifier(n, max_features=None)\n",
    "    scikitForest = scikitForest.fit(trainIn, trainOut)\n",
    "    scikitPredictions_test = scikitForest.predict(testIn)\n",
    "    accuracies_scikit_test[i] = accuracy(scikitPredictions_test, testOut)\n",
    "    scikitPredictions_train = scikitForest.predict(trainIn)\n",
    "    accuracies_scikit_train[i] = accuracy(scikitPredictions_train, trainOut)\n",
    "    print(\"{} Trees:\\nFrom scratch accuracy train/test = {:.3f}/{:.3f}\\nScikit accuracy train/test = {:.3f}/{:.3f}\\n\".format(n, accuracies_scratch_train[i], accuracies_scratch_test[i], accuracies_scikit_train[i], accuracies_scikit_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(5)\n",
    "plt.plot(ns.astype('str'), list(accuracies_scratch_test), 'ko-', label=\"Random Forest From Scratch Test Accuracy\")\n",
    "plt.plot(ns.astype('str'), list(accuracies_scikit_test), 'mo-', label=\"Random Forest From Scikit Learn Test Accuracy\")\n",
    "plt.plot(ns.astype('str'), list(accuracies_scratch_train), 'ks--', label=\"Random Forest From Scratch Training Accuracy\")\n",
    "plt.plot(ns.astype('str'), list(accuracies_scikit_train), 'ms--', label=\"Random Forest From Scikit Learn Training Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Classification Accuracy (% Correct)')\n",
    "plt.xlabel('Number of Trees (n)')\n",
    "plt.ylim([0,108])\n",
    "plt.xticks(np.arange(ns.shape[0]),ns)\n",
    "plt.title(\"Classifier Accuracy vs Number of Trees in Forest\")\n",
    "\n",
    "for i in range(ns.shape[0]):\n",
    "    label_scratch = \"{:.2f}\".format(accuracies_scratch_test[i])\n",
    "    plt.annotate(label_scratch,(i-0.1,accuracies_scikit_test[i]-4))\n",
    "\n",
    "    label_scikit = \"{:.2f}\".format(accuracies_scikit_test[i])\n",
    "    plt.annotate(label_scikit,(i-0.1,accuracies_scikit_test[i]-6), color='m')\n",
    "\n",
    "    label_scikit = \"{:.2f}\".format(accuracies_scratch_train[i])\n",
    "    plt.annotate(label_scikit,(i-0.1,accuracies_scikit_train[i]+2))\n",
    "\n",
    "    label_scikit = \"{:.2f}\".format(accuracies_scikit_train[i])\n",
    "    plt.annotate(label_scikit,(i-0.1,accuracies_scikit_train[i]+4), color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Tree Tests sklearn v scratch implementation\n",
    "preformaceSklearn = []\n",
    "preformaceScratch = []\n",
    "\n",
    "for i in range(10):\n",
    "    trainData, testData = splitData(dataset)\n",
    "    xtestIn,yTestOut=separateInputOutput(testData)\n",
    "    xtrainIn,yTrainOut = separateInputOutput(trainData)\n",
    "\n",
    "    #Test tree script developed from scratch\n",
    "    treeScratch = createTree(xtrainIn,yTrainOut) \n",
    "    predictedYScratch = []\n",
    "    for i in range(len(xtestIn)):\n",
    "        predictionScratch = predictTree(xtestIn[i],treeScratch)\n",
    "        predictedYScratch.append(predictionScratch)\n",
    "    preformaceScratch.append(accuracy(predictedYScratch,yTestOut))\n",
    "    \n",
    "    #Sklearn \n",
    "    treeSklearn = tree.DecisionTreeClassifier()\n",
    "    treeSklearn = treeSklearn.fit(xtrainIn, yTrainOut)\n",
    "    sklearnTestPrdictionsTree  = treeSklearn.predict(xtestIn)\n",
    "    preformaceSklearn.append(accuracy(sklearnTestPrdictionsTree,yTestOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(5)\n",
    "plt.plot(preformaceScratch,c='black',marker = '.',label=\"Decision Tree From Scratch\")\n",
    "plt.plot(preformaceSklearn,c='purple',marker = '.',label=\"Decision Tree From Scikit Learn\")\n",
    "plt.legend()\n",
    "plt.title(label = 'Scikit Learn vs Scratch Implementation')\n",
    "plt.ylim([50,100])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Preformance')\n",
    "for i in range(len(preformaceScratch)):\n",
    "    label_scratch = \"{:.2f}\".format(preformaceScratch[i])\n",
    "    plt.annotate(label_scratch,(i-0.1,60))\n",
    "\n",
    "    label_scikit = \"{:.2f}\".format(preformaceSklearn[i])\n",
    "    plt.annotate(label_scikit,(i-0.1,63), color='m')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Average Performance using Scikit Learn Decision Tree Implementation\",\"{:.4f}%\".format(sum(preformaceSklearn)/len(preformaceSklearn)))\n",
    "print(\"Average Performance using Decision Tree Implementation Made from Scratch\",\"{:.4f}%\".format(sum(preformaceScratch)/len(preformaceScratch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 10\n",
    "n_trees = 50\n",
    "\n",
    "noNorm = []\n",
    "rangeNorm = []\n",
    "zNorm = []\n",
    "\n",
    "trainIn_rangeNorm = normaliseData(trainIn, 'range')\n",
    "testIn_rangeNorm = normaliseData(testIn, 'range')\n",
    "\n",
    "trainIn_zNorm = normaliseData(trainIn, 'z')\n",
    "testIn_zNorm = normaliseData(testIn, 'z')\n",
    "\n",
    "for i in range(reps):\n",
    "    print(\"Iteration\",i)\n",
    "\n",
    "    forest = randomForestClassifierScratch(trainIn,trainOut,n_trees)\n",
    "    predicty = predictForest(testIn,forest)\n",
    "    acc = accuracy(predicty,testOut)\n",
    "    print(\"No norm accuracy = \", acc)\n",
    "    noNorm.append(acc)\n",
    "\n",
    "    forest = randomForestClassifierScratch(trainIn_rangeNorm,trainOut,n_trees)\n",
    "    predicty = predictForest(testIn_rangeNorm,forest)\n",
    "    acc = accuracy(predicty,testOut)\n",
    "    print(\"Range norm accuracy = \", acc)\n",
    "    rangeNorm.append(acc)\n",
    "\n",
    "    forest = randomForestClassifierScratch(trainIn_zNorm,trainOut,n_trees)\n",
    "    predicty = predictForest(testIn_zNorm,forest)\n",
    "    acc = accuracy(predicty,testOut)\n",
    "    print(\"Z norm accuracy = \", acc)\n",
    "    zNorm.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEANS\n",
    "print(\"Mean no norm = {:3f}\".format(np.array(noNorm).mean()))\n",
    "print(\"Mean range norm = {:3f}\".format(np.array(rangeNorm).mean()))\n",
    "print(\"Mean z norm = {:3f}\".format(np.array(zNorm).mean()))\n",
    "\n",
    "# PLOT\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(5)\n",
    "plt.title(\"Effect Of Normalisation On Random Forest Beer Classifier Accuracy\")\n",
    "plt.plot(noNorm, 'ko-', label='No Normalisation')\n",
    "plt.plot(rangeNorm, 'bo-', label='Range Normalisation')\n",
    "plt.legend()\n",
    "plt.plot(zNorm, 'go-', label='Z Normalisation')\n",
    "plt.ylim([50,100])\n",
    "plt.xlabel(\"Test #\")\n",
    "plt.ylabel(\"Classification Accuracy (% correct)\")\n",
    "plt.xticks(np.arange(len(noNorm)),np.linspace(1,len(noNorm),len(noNorm)).astype(np.int))\n",
    "plt.legend()\n",
    "for i in range(reps):\n",
    "    label_noNorm = \"{:.2f}\".format(noNorm[i])\n",
    "    plt.annotate(label_noNorm,(i-0.1,rangeNorm[i]-3), color='k')\n",
    "\n",
    "    label_rangeNorm = \"{:.2f}\".format(rangeNorm[i])\n",
    "    plt.annotate(label_rangeNorm,(i-0.1,rangeNorm[i]-7), color='b')\n",
    "\n",
    "    label_zNorm = \"{:.2f}\".format(zNorm[i])\n",
    "    plt.annotate(label_zNorm,(i-0.1,rangeNorm[i]-5), color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preformaceSklearnForest = []\n",
    "preformaceScratchForest = []\n",
    "\n",
    "for i in range(10):\n",
    "    trainData, testData = splitData(dataset)\n",
    "    xtestIn,yTestOut=separateInputOutput(testData)\n",
    "    xtrainIn,yTrainOut = separateInputOutput(trainData)\n",
    "\n",
    "    #Scratch implementation of forest classifier\n",
    "    forestTest = randomForestClassifierScratch(xtrainIn,yTrainOut,50)\n",
    "    predictYval = predictForest(xtestIn,forestTest)\n",
    "    preformaceScratchForest.append(accuracy(predictYval,yTestOut))\n",
    "\n",
    "    #sklearn\n",
    "    rfcSklearnTest = RandomForestClassifier(50, max_features=None)\n",
    "    rfcSklearnTest = rfcSklearnTest.fit(xtrainIn, yTrainOut)\n",
    "    sklearnTrainPredictionsTest = rfcSklearnTest.predict(xtestIn)\n",
    "    preformaceSklearnForest.append(accuracy(sklearnTrainPredictionsTest,yTestOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(5)\n",
    "plt.plot(preformaceScratchForest,c='black',marker = '.',label=\"Random Forest From Scratch\")\n",
    "plt.plot(preformaceSklearnForest,c='purple',marker = '.',label=\"Random Forest From Scikit Learn\")\n",
    "plt.title(label = 'Scikit Learn vs Scratch Implementation')\n",
    "plt.legend()\n",
    "plt.ylim([50,100])\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.ylabel('Preformance')\n",
    "for i in range(len(preformaceSklearnForest)):\n",
    "    label_scratch = \"{:.2f}\".format(preformaceScratchForest[i])\n",
    "    plt.annotate(label_scratch,(i-0.1,60))\n",
    "\n",
    "    label_scikit = \"{:.2f}\".format(preformaceSklearnForest[i])\n",
    "    plt.annotate(label_scikit,(i-0.1,63), color='m')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Average Performance using Scikit Learn Randon Forest Implementation\",\"{:.4f}%\".format(sum(preformaceSklearnForest)/len(preformaceSklearnForest)))\n",
    "print(\"Average Performance using Randon Forest Implementation Made from Scratch\",\"{:.4f}%\".format(sum(preformaceScratchForest)/len(preformaceScratchForest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}